{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#open-data-contract-standard-odcs","title":"Open Data Contract Standard (ODCS)","text":"<p>Welcome! </p> <p>Thanks for your interest and for taking the time to come here! \u2764\ufe0f</p>"},{"location":"#executive-summary","title":"Executive summary","text":"<p>This standard describes a structure for a data contract. It's current version is 2.2.1. It is available for you as an Apache 2.0 license. Contributions are welcome!</p>"},{"location":"#discover-the-open-standard","title":"Discover the open standard","text":"<p>Discover the Open Data Contract Standard. This file contains some explanations and several examples. More examples have been added to v2.2.1.</p>"},{"location":"#what-is-a-data-contract","title":"What is a Data Contract?","text":""},{"location":"#the-basics-of-a-data-contract","title":"The basics of a data contract","text":"<p>A data contract defines the agreement between a data producer and consumers. A data contract contains several sections: * Fundamentals. * Schema. * Data quality. * Service-level agreement (SLA). * Security &amp; stakeholders. * Custom properties.</p> <p></p> <p>Figure 1: illustration of a data contract, its principal contributors, sections, and usage.</p>"},{"location":"#json-schema","title":"JSON Schema","text":"<p>JSON Schema for ODCS can be found here. You can import this schema into your IDE for  validation of your YAML files. Links below show how you can import the schema:</p> <ul> <li>IntelliJ</li> <li>VS Code</li> </ul>"},{"location":"#contributing-to-the-project","title":"Contributing to the project","text":"<p>Check out the CONTRIBUTING file.</p>"},{"location":"#articles","title":"Articles","text":"<ul> <li>2023-11-30 - Linux Foundation AI &amp; Data - Bitol Joins LF AI &amp; Data as New Sandbox Project</li> <li>2023-11-30 - AIDAUG - Bitol Joins LF AI &amp; Data as New Sandbox Project</li> <li>2023-10-01 - Data Contracts: A Bridge Connecting Two Worlds</li> <li>2023-09-10 - Data Contracts 101</li> <li>2023-08-10 - Welcome to the Open Data Contract Standard</li> <li>2023-05-11 - Data Contracts \u2013 Everything You Need to Know</li> <li>2023-05-07 - Data Engineering Weekly #130 - Data Contract in the Wild with PayPal\u2019s Data Contract Template</li> <li>2023-05-06 - PayPal \u0e40\u0e1b\u0e34\u0e14 Data Contract \u0e40\u0e1b\u0e47\u0e19 Open Source Template \u0e43\u0e2b\u0e49\u0e44\u0e1b\u0e43\u0e0a\u0e49\u0e07\u0e32\u0e19\u0e01\u0e31\u0e19</li> <li>2023-05-05 - Jonathan Neo (j__neo ) on Reddit</li> <li>2023-05-01 - PayPal open sources its data contract template</li> </ul> <p>If you spot an article about the Open Data Contract Standard, make a pull request! </p>"},{"location":"#more","title":"More","text":""},{"location":"#history","title":"History","text":"<p>Formerly known as the data contract template, this standard is used to implement Data Mesh at PayPal. Today, starting with v2.2.0, it is maintained by a 501c6 non-profit organization called AIDA User Group (Artificial Intelligence, Data, and Analytics User Group). On November 30th, 2023, AIDA User Group and the Linux Foundation AI &amp; Data joined forces to create Bitol. Bitol englobes ODCS and future standards &amp; tools.</p>"},{"location":"#how-does-paypal-use-data-contracts","title":"How does PayPal use Data Contracts?","text":"<p>PayPal uses data contracts in many ways, but this article from the PayPal Technology blog gives a good introduction.</p>"},{"location":"contributing/","title":"Open Data Contract Standard","text":""},{"location":"contributing/#executive-summary","title":"Executive summary","text":"<p>First off, thanks for taking the time to contribute! \u2764\ufe0f</p> <p>All types of contributions are encouraged and valued. See the Table of Contents for different ways to help and details about how this project handles them. Please make sure to read the relevant section before making your contribution. It will make it a lot easier for us maintainers and smooth out the experience for all involved. The community looks forward to your contributions. \ud83c\udf89</p> <p>You do not have to be a member of AIDA User Group to contribute, although becoming a member is free. Strength is always in the number. Check it out.</p> <p>And if you like the project, but just don't have time to contribute, that's fine. There are other easy ways to support the project and show your appreciation, which we would also be very happy about: - Star the project. - Tweet about it. - Refer this project in your project's readme. - Mention the project at local meetups and tell your friends/colleagues.</p>"},{"location":"contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Code of Conduct</li> <li>I Have a Question</li> <li>I Want To Contribute</li> <li>Suggesting Enhancements</li> <li>Improving The Documentation</li> <li>Join The Project Team</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project and everyone participating in it is governed by the Open Data Contract Standard Code of Conduct. By participating, you are expected to uphold this code. Please report unacceptable behavior to @jgperrin.</p>"},{"location":"contributing/#i-have-a-question","title":"I Have a Question","text":"<p> New </p> <p>AIDA User Group also opened its Slack for Data Contract discussion. It is an alternate way of contributing to this project. The Slack channel is now available.</p> <p>You have to be a member of AIDA User Group (it's free) to have access to our Slack channel. All the details are here.</p> <p>If you want to ask a question, we assume that you have read the available Documentation.</p> <p>Before you ask a question, it is best to search for existing Issues that might help you. In case you have found a suitable issue and still need clarification, you can write your question in this issue. It is also advisable to search the internet for answers first.</p> <p>If you then still feel the need to ask a question and need clarification, we recommend the following:</p> <ul> <li>Open an Issue.</li> <li>Provide as much context as you can about what you're running into.</li> </ul> <p>We will then take care of the issue as soon as possible.</p>"},{"location":"contributing/#i-want-to-contribute","title":"I Want To Contribute","text":""},{"location":"contributing/#legal-notice","title":"Legal Notice","text":"<p>When contributing to this project, you must agree that you have authored 100% of the content, that you have the necessary rights to the content and that the content you contribute may be provided under the project license.</p>"},{"location":"contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>This section guides you through submitting an enhancement suggestion for Data Contract Template, including completely new features and minor improvements to existing functionality. Following these guidelines will help maintainers and the community to understand your suggestion and find related suggestions.</p>"},{"location":"contributing/#before-submitting-an-enhancement","title":"Before Submitting an Enhancement","text":"<ul> <li>Make sure that you are using the latest version.</li> <li>Read the documentation carefully and find out if the functionality is already covered.</li> <li>Perform a search to see if the enhancement has already been suggested. If it has, add a comment to the existing issue instead of opening a new one.</li> <li>Find out whether your idea fits with the scope and aims of the project. It's up to you to make a strong case to convince the project's developers of the merits of this feature. Keep in mind that we want features that will be useful to the majority of our users and not just a small subset. </li> </ul>"},{"location":"contributing/#how-do-i-submit-a-good-enhancement-suggestion","title":"How Do I Submit a Good Enhancement Suggestion?","text":"<p>Enhancement suggestions are tracked as GitHub issues.</p> <ul> <li>Use a clear and descriptive title for the issue to identify the suggestion.</li> <li>Provide a step-by-step description of the suggested enhancement in as many details as possible.</li> <li>Describe the current behavior and explain which behavior you expected to see instead and why. At this point you can also tell which alternatives do not work for you.</li> <li>Explain why this enhancement would be useful to most Open Data Contract Standard users. You may also want to point out the other projects that solved it better and which could serve as inspiration.</li> </ul>"},{"location":"contributing/#improving-the-documentation","title":"Improving The Documentation","text":"<p>Please contact @jgperrin. Examples are always welcome.</p>"},{"location":"contributing/#join-the-project-team","title":"Join The Project Team","text":"<p>Please contact @jgperrin.</p>"},{"location":"standard/","title":"Open Data Contract Standard","text":""},{"location":"standard/#executive-summary","title":"Executive summary","text":"<p>This document describes the keys and values expected in a YAML data contract, per the Open Data Contract Standard. It is divided in multiple sections: demographics, dataset &amp; schema, data quality, pricing, stakeholders, roles, service-level agreement, and other properties. Each section starts with at least an example followed by definition of each field/key.</p>"},{"location":"standard/#table-of-content","title":"Table of content","text":"<ul> <li>Fundamentals &amp; demographics</li> <li>Datasets &amp; schema</li> <li>Data quality</li> <li>Pricing</li> <li>Stakeholders</li> <li>Roles</li> <li>Service-level agreement</li> <li>Other properties</li> <li>Full example</li> </ul>"},{"location":"standard/#notes","title":"Notes","text":"<ul> <li>This contract is containing example values, we reviewed very carefully the consistency of those values, but we cannot guarantee that there are no errors. If you spot one, please raise an issue.</li> <li>Some fields have <code>null</code> value: even if it is equivalent to not having the field in the contract, we wanted to have the field for illustration purpose.</li> <li>This contract leverages BigQuery but should be platform agnostic. If you think it is not the case, please raise an issue.</li> </ul>"},{"location":"standard/#demographics","title":"Demographics","text":"<p>This section contains general information about the contract.</p>"},{"location":"standard/#example","title":"Example","text":"<pre><code># What's this data contract about?\ndatasetDomain: seller # Domain\nquantumName: my quantum # Data product name\nuserConsumptionMode: Analytical\nversion: 1.1.0 # Version (follows semantic versioning)\nstatus: current\nuuid: 53581432-6c55-4ba2-a65f-72344a91553a\n# Lots of information\ndescription:\npurpose: Views built on top of the seller tables.\nlimitations: null\nusage: null\ntenant: ClimateQuantumInc\n# Getting support\nproductDl: product-dl@ClimateQuantum.org\nproductSlackChannel: '#product-help'\nproductFeedbackUrl: null\n# Physical parts / GCP / BigQuery specific\nsourcePlatform: googleCloudPlatform\nsourceSystem: bigQuery\nproject: edw # BQ dataset\ndatasetName: access_views # BQ dataset\nkind: DataContract\napiVersion: 2.3.0 # Standard version (follows semantic versioning, previously known as templateVersion)\ntype: tables\n# Physical access\ndriver: null\ndriverVersion: null\nserver: null\ndatabase: pypl-edw.pp_access_views\nusername: '${env.username}'\npassword: '${env.password}'\nschedulerAppName: name_coming_from_scheduler # NEW 2.1.0 Required if you want to schedule stuff, comes from DataALM.\n# Data Quality\nquality: null # See more information below\n# Tags\ntags: null\n</code></pre>"},{"location":"standard/#definitions","title":"Definitions","text":"Key UX label Required Description datasetDomain Dataset domain No Name of the logical domain dataset the contract describes. This field is only required for output data contracts. Examples: <code>imdb_ds_aggregate</code>, <code>receiver_profile_out</code>,  <code>transaction_profile_out</code>. quantumName Quantum name Yes The name of the data quantum or data product. userConsumptionMode Consumption mode No List of data modes for which the dataset may be used.  Expected sample values might be <code>analytical</code> or <code>operational</code>. Note: in the future, this will probably be replaced by ports. version Version Yes Current version of the data contract. status Status Yes Current status of the dataset. Valid values are <code>production</code>, <code>test</code>, or <code>development</code>. uuid Identifier Yes A unique identifier used to reduce the risk of dataset name collisions; initially the UUID will be created using a UUID generator tool (example). However, we may want to develop a method that accepts a seed value using a combination of fields\u2013such as name, kind and source\u2013to create a repeatable value. description Description No Object. description.purpose Purpose No Purpose of the dataset, table, or column (depending on the level); the key may appear at the dataset, table, or column level. description.limitations Limitations No Limitations of the dataset, table, or column (depending on the level); the key may appear at the dataset, table, or column level. description.usage Usage No Intended usage of the dataset, table, or column (depending on the level); the key may appear at the dataset, table, or column level. tenant Tenant No Indicates the property the data is primarily associated with. Value is case insensitive. productDl E-mail distribution list No The email distribution list (DL) of the persons or team responsible for maintaining the dataset. productSlackChannel Support Slack channel No Slack channel of the team responsible for maintaining the dataset. productFeedbackUrl Feedback URL No The URL for submitting feedback to the team responsible for maintaining the dataset. sourcePlatform Source platform No The platform where the dataset resides. Expected value is GoogleCloudPlatform, IBMCloud, Azure... sourceSystem Source system No The system where the dataset resides. Expected value can be BigQuery. project Project No Associated cloud project name, can be used for billing or administrative purpose. Used to be datasetProject. datasetName Dataset name No May be required in cloud instance like GCP BigQuery dataset name. server Server No The server where the dataset resides. kind Kind Yes The kind of file this is. Valid value is <code>DataContract</code>. apiVersion Standard version No Version of the standard used to build data contract. Default value is v2.2.2. type Type Yes Identifies the types of objects in the dataset. For BigQuery or any other database, the expected value would be Tables. driver Driver No The connection driver required to connect to the dataset. driverVersion Driver version No The version of the connection driver to be used to connect to the dataset. username Username No User credentials for connecting to the dataset; how the credentials will be stored/passed is outside of the scope of the contract. password Password No User credentials for connecting to the dataset; how the credentials will be stored/passed is out of the scope of this contract. schedulerAppName Scheduler App Name No Required if you want to schedule stuff. The name of the application used to schedule jobs"},{"location":"standard/#dataset-and-schema","title":"Dataset and schema","text":"<p>This section describes the dataset and the schema of the data contract. It is the support for data quality, which is detailed in the next section.</p>"},{"location":"standard/#example_1","title":"Example","text":"<pre><code>dataset:\n- table: tbl\nphysicalName: tbl_1 # NEW in v2.1.0, Optional, default value is table name + version separated by underscores, as table_1_2_0\npriorTableName: null # if needed\ndescription: Provides core payment metrics authoritativeDefinitions: # NEW in v2.2.0, inspired by the column-level authoritative links\n- url: https://catalog.data.gov/dataset/air-quality type: businessDefinition\n- url: https://youtu.be/jbY1BKFj9ec\ntype: videoTutorial\ntags: null\ndataGranularity: Aggregation on columns txn_ref_dt, pmt_txn_id\ncolumns:\n- column: txn_ref_dt\nisPrimary: false # NEW in v2.1.0, Optional, default value is false, indicates whether the column is primary key in the table.\nprimaryKeyPosition: -1\nbusinessName: transaction reference date\nlogicalType: date\nphysicalType: date\nisNullable: false\ndescription: null\npartitionStatus: true\npartitionKeyPosition: 1\nclusterStatus: false\nclusterKeyPosition: -1\ncriticalDataElementStatus: false\ntags: []\nclassification: public\ntransformSourceTables:\n- table_name_1\n- table_name_2\n- table_name_3\ntransformLogic: sel t1.txn_dt as txn_ref_dt from table_name_1 as t1, table_name_2 as t2, table_name_3 as t3 where t1.txn_dt=date-3\ntransformDescription: Defines the logic in business terms. sampleValues:\n- 2022-10-03\n- 2020-01-28\n- column: rcvr_id\nisPrimary: true # NEW in v2.1.0, Optional, default value is false, indicates whether the column is primary key in the table.\nprimaryKeyPosition: 1\nbusinessName: receiver id\nlogicalType: string\nphysicalType: varchar(18)\nisNullable: false\ndescription: A description for column rcvr_id.\npartitionStatus: false\npartitionKeyPosition: -1\nclusterStatus: true\nclusterKeyPosition: 1\ncriticalDataElementStatus: false\ntags: []\nclassification: restricted\nencryptedColumnName: enc_rcvr_id\n- column: rcvr_cntry_code\nisPrimary: false # NEW in v2.1.0, Optional, default value is false, indicates whether the column is primary key in the table.\nprimaryKeyPosition: -1\nbusinessName: receiver country code\nlogicalType: string\nphysicalType: varchar(2)\nisNullable: false\ndescription: null\npartitionStatus: false\npartitionKeyPosition: -1\nclusterStatus: false\nclusterKeyPosition: -1\ncriticalDataElementStatus: false\ntags: []\nclassification: public\nauthoritativeDefinitions:\n- url: https://collibra.com/asset/742b358f-71a5-4ab1-bda4-dcdba9418c25\ntype: businessDefinition\n- url: https://github.com/myorg/myrepo\ntype: transformationImplementation\n- url: jdbc:postgresql://localhost:5432/adventureworks/tbl_1/rcvr_cntry_code\ntype: implementation\nencryptedColumnName: rcvr_cntry_code_encrypted\n</code></pre>"},{"location":"standard/#definitions_1","title":"Definitions","text":"Key UX label Required Description dataset Dataset Yes Array. A list of tables within the dataset to be cataloged. dataset.table Table Yes Name of the table being cataloged; the value should only contain the table name. Do not include the project or dataset name in the value. dataset.table.physicalName Physical Name No Physical name of the table, default value is table name + version separated by underscores, as <code>table_1_2_0</code>. dataset.table.priorTableName Prior Table Name No Name of the previous version of the dataset, if applicable. dataset.table.description Description No Description of the dataset. dataset.table.authoritativeDefinitions Authoritative Definitions No List of links to sources that provide more details on the table; examples would be a link to an external definition, a training video, a GitHub repo, Collibra, or another tool. Authoritative definitions follow the same structure in the standard. dataset.table.dataGranularity Data Granularity No Granular level of the data in the table. Example would be <code>pmt_txn_id</code>. dataset.table.columns Columns Yes Array. A list of columns in the table. dataset.table.columns.column Column Yes The name of the column. dataset.table.columns.column.isPrimaryKey Primary Key No Boolean value specifying whether the column is primary or not. Default is false. dataset.table.columns.column.primaryKeyPosition Primary Key Position No If column is a primary key, the position of the primary key column. Starts from 1. Example of <code>account_id, name</code> being primary key columns, <code>account_id</code> has primaryKeyPosition 1 and <code>name</code> primaryKeyPosition 2. Default to -1. dataset.table.columns.column.businessName Business Name No The business name of the column. dataset.table.columns.column.logicalType Logical Type Yes The logical column datatype. dataset.table.columns.column.physicalType Physical Type Yes The physical column datatype. dataset.table.columns.column.description Description No Description of the column. dataset.table.columns.column.isNullable Nullable No Indicates if the column may contain Null values; possible values are true and false. Default is false. dataset.table.columns.column.isUnique Unique No Indicates if the column contains unique values; possible values are true and false. Default is false. dataset.table.columns.column.partitionStatus Partition Status No Indicates if the column is partitioned; possible values are true and false. dataset.table.columns.column.partitionKeyPosition Partition Key Position No If column is used for partitioning, the position of the partition column. Starts from 1. Example of <code>country, year</code> being partition columns, <code>country</code> has partitionKeyPosition 1 and <code>year</code> partitionKeyPosition 2. Default to -1. dataset.table.columns.column.clusterStatus Cluster Status No Indicates of the column is clustered; possible values are true and false. dataset.table.columns.column.clusterKeyPosition Cluster Key Position No If column is used for clustering, the position of the cluster column. Starts from 1. Example of <code>year, date</code> being cluster columns, <code>year</code> has clusterKeyPosition 1 and <code>date</code> clusterKeyPosition 2. Default to -1. dataset.table.columns.column.classification Classification No Can be anything, like confidential, restricted, and public to more advanced categorization. Some companies like PayPal, use data classification indicating the class of data in the column; expected values are 1, 2, 3, 4, or 5. dataset.table.columns.column.authoritativeDefinitions Authoritative Definitions No List of links to sources that provide more detail on column logic or values; examples would be URL to a GitHub repo, Collibra, on another tool. dataset.table.columns.column.encryptedColumnName Encrypted Column Name No The column name within the table that contains the encrypted column value. For example, unencrypted column <code>email_address</code> might have an encryptedColumnName of <code>email_address_encrypt</code>. dataset.table.columns.column.transformSourceTables Transform Source Tables No List of sources used in column transformation. dataset.table.columns.column.transformLogic Transform Logic No Logic used in the column transformation. dataset.table.columns.column.transformDescription Transform Description No Describes the transform logic in very simple terms. dataset.table.columns.column.sampleValues Sample Values No List of sample column values. dataset.table.columns.column.criticalDataElementStatus Critical Data Element Status No True or false indicator; If element is considered a critical data element (CDE) then true else false. dataset.table.columns.column.tags Tags No A list of tags that may be assigned to the dataset, table or column; the tags keyword may appear at any level."},{"location":"standard/#authorative-definitions","title":"Authorative definitions","text":"<p>Updated in ODCS (Open Data Contract Standard) v2.2.1.</p> Key UX label Required Description type Definition type Yes Type of definition for authority: v2.2.1 adds standard values: <code>businessDefinition</code>, <code>transformationImplementation</code>, <code>videoTutorial</code>, <code>tutorial</code>, and <code>implementation</code>. url URL to definition Yes URL to the authority."},{"location":"standard/#data-quality","title":"Data quality","text":"<p>This section describes data quality rules &amp; parameters. They are tightly linked to the schema described in the previous section.</p>"},{"location":"standard/#example-of-data-quality-at-the-dataset-level","title":"Example of data quality at the dataset level","text":"<p>Note: * This example relies on a data quality tool called Elevate. It should be easily transformed to any other tool. If you have questions, please raise an issue. * The Open Data Contract Standard has a provision for supporting multiple data quality tools.</p> <pre><code>dataset:\n- table: tab1\n# ...\nquality:\n- code: countCheck # Required, name of the rule\ntemplateName: CountCheck # NEW in v2.1.0 Required\ndescription: Ensure row count is within expected volume range       # Optional\ntoolName: Elevate # Required\ntoolRuleName: DQ.rw.tab1.CountCheck # NEW in v2.1.0 Optional (Available only to the users who can change in source code edition)\ndimension: completeness                                             # Optional\ntype: reconciliation                                                # Optional NEW in v2.1.0 default value for column level check - dataQuality and for table level reconciliation\nseverity: error                                                     # Optional NEW in v2.1.0, default value is error\nbusinessImpact: operational                                         # Optional NEW in v2.1.0\nscheduleCronExpression: 0 20 * * *                                  # Optional NEW in v2.1.0 default schedule - every day 10 a.m. UTC\n- code: distinctCheck    description: enforce distinct values\ntoolName: Elevate\ntemplateName: DistinctCheck\ndimension: completeness\ntoolRuleName: DQ.rw.tab1.DistinctCheck\ncolumns:\n- txn_ref_dt\n- rcvr_id\ncolumn: null\ntype: reconciliation\nseverity: error\nbusinessImpact: operational\nscheduleCronExpression: 0 20 * * *\ncustomProperties:                     - property: FIELD_NAME\nvalue: rcvr_id\n- property: FILTER_CONDITIONS\nvalue: 1&gt;0\n- code: piiCheck\ndescription: null\ntoolName: Elevate\ntemplateName: PIICheck\ntoolRuleName: DQ.rw.tab1_2_0_0.piiCheck\ntype: dataQuality\nseverity: error\nbusinessImpact: operational\nscheduleCronExpression: 0 20 * * *\ncustomProperties:                     - property: FIELD_NAME\nvalue:\n- property: FILTER_CONDITIONS\nvalue:\n</code></pre>"},{"location":"standard/#example-of-data-quality-at-the-column-level","title":"Example of data quality at the column level","text":"<pre><code>dataset:\n- table: tab1\n- column: rcvr_id\nisPrimary: true # NEW in v2.1.0, Optional, default value is false, indicates whether the column is primary key in the table.\nbusinessName: receiver id\n# ...\nquality:\n- code: nullCheck\ntemplateName: NullCheck\ndescription: column should not contain null values\ntoolName: Elevate\ntoolRuleName: DQ.rw.tab1_2_0_0.rcvr_cntry_code.NullCheck\ndimension: completeness # dropdown 7 values\ntype: dataQuality\nseverity: error\nbusinessImpact: operational\nscheduleCronExpression: 0 20 * * *\ncustomProperties:\n- property: FIELD_NAME\nvalue:\n- property: COMPARE_TO\nvalue:\n- property: COMPARISON_TYPE\nvalue: Greater than\n</code></pre>"},{"location":"standard/#definitions_2","title":"Definitions","text":"Key UX label Required Description quality Quality No Quality tag with all the relevant information for rule setup and execution. quality.code Quality Code No The Rosewall data quality code(s) indicating which quality checks need to be performed at the dataset, table, or column level. The quality keyword may appear at any level. Some quality checks require parameters, so the check can be completed (e.g., a list of fields used to identify a distinct row). Therefore, some quality checks may be followed by a single value or an array. See the appendix for a link to quality checks. quality.templateName Template Name Yes The template name that indicates what is the equivalent template from the tool. quality.description Description No Describe the quality check to be completed. quality.toolName Tool Name Yes Name of the tool used to complete the quality check; Most will be Elevate initially. quality.toolRuleName Tool Rule Name No Name of the quality tool's rule created to complete the quality check. quality.dimension Dimension No The key performance indicator (KPI) or dimension for data quality. quality.columns Columns No List of columns to be used in the quality check. quality.column Column No To be used in lieu of quality.columns when only a single column is required for the quality check. quality.type Type No The type of quality check. quality.severity Severity No The severity of the quality rule. quality.businessImpact Business Impact No Consequences of the rule failure. quality.scheduleCronExpression Schedule Expression No Rule execution schedule details. quality.customProperties Custom Properties No Additional properties required for rule execution."},{"location":"standard/#pricing","title":"Pricing","text":"<p>This section covers pricing when you bill your customer for using this data product. Pricing is experimental in v2.1.1 of the data contract.</p>"},{"location":"standard/#example_2","title":"Example","text":"<pre><code>price:\npriceAmount: 9.95\npriceCurrency: USD\npriceUnit: megabyte\n</code></pre>"},{"location":"standard/#definitions_3","title":"Definitions","text":"Key UX label Required Description price Price No Object price.priceAmount Price Amount No Subscription price per unit of measure in <code>priceUnit</code>. price.priceCurrency Price Currency No Currency of the subscription price in <code>price.priceAmount</code>. price.priceUnit Price Unit No The unit of measure for calculating cost. Examples megabyte, gigabyte."},{"location":"standard/#stakeholders","title":"Stakeholders","text":"<p>This section lists stakeholders and the history of their relation with this data contract.</p>"},{"location":"standard/#example_3","title":"Example","text":"<pre><code>stakeholders:\n- username: ceastwood\nrole: Data Scientist\ndateIn: 2022-08-02\ndateOut: 2022-10-01\nreplacedByUsername: mhopper\n- username: mhopper\nrole: Data Scientist\ndateIn: 2022-10-01\n- username: daustin\nrole: Owner\ncomment: Keeper of the grail\ndateIn: 2022-10-01\n</code></pre>"},{"location":"standard/#definitions_4","title":"Definitions","text":"<p>The UX label is the label used in the UI and other user experiences. It is not limited to BlueRacket.</p> Key UX label Required Description stakeholders Stakeholders No Array stakeholders.username Username No The stakeholder's username or email. stakeholders.role Role No The stakeholder's job role; Examples might be owner, data steward. There is no limit on the role. stakeholders.dateIn Date In No The date when the user became a stakeholder. stakeholders.dateOut Date Out No The date when the user ceased to be a stakeholder stakeholders.replacedByUsername Replaced By Username No The username of the user who replaced the stakeholder"},{"location":"standard/#roles","title":"Roles","text":"<p>This section lists the roles that a consumer may need to access the dataset depending on the type of access they require.</p>"},{"location":"standard/#example_4","title":"Example","text":"<pre><code>roles:\n- role: microstrategy_user_opr\naccess: read\nfirstLevelApprovers: Reporting Manager\nsecondLevelApprovers: 'mandolorian'\n- role: bq_queryman_user_opr\naccess: read\nfirstLevelApprovers: Reporting Manager\nsecondLevelApprovers: na\n- role: risk_data_access_opr\naccess: read\nfirstLevelApprovers: Reporting Manager\nsecondLevelApprovers: 'dathvador'\n- role: bq_unica_user_opr\naccess: write\nfirstLevelApprovers: Reporting Manager\nsecondLevelApprovers: 'mickey'\n</code></pre>"},{"location":"standard/#definitions_5","title":"Definitions","text":"Key UX label Required Description roles Roles Yes Array. A list of roles that will provide user access to the dataset. roles.role Role Yes Name of the IAM role that provides access to the dataset; the value will generally come directly from the \"BQ dataset to IAM roles mapping\" document. roles.access Access Yes The type of access provided by the IAM role; the value will generally come directly from the \"BQ dataset to IAM roles mapping\" document. roles.firstLevelApprovers 1st Level Approvers No The name(s) of the first-level approver(s) of the role; the value will generally come directly from the \"BQ dataset to IAM roles mapping\" document. roles.secondLevelApprovers 2nd Level Approvers No The name(s) of the second-level approver(s) of the role; the value will generally come directly from the \"BQ dataset to IAM roles mapping\" document."},{"location":"standard/#service-level-agreement","title":"Service-level agreement","text":"<p>This section describes the service-level agreements (SLA). SLA have been extended in version v2.1.0.</p> <ul> <li>Use the <code>Table.Column</code> to indicate the number to do the checks on, as in <code>SELECT txn_ref_dt FROM tab1</code>.</li> <li>Separate multiple table.columns by a comma, as in <code>table1.col1</code>, <code>table2.col1</code>, <code>table1.col2</code>.</li> <li>If there is only one table in the contract, the table name is not required.</li> </ul>"},{"location":"standard/#example_5","title":"Example","text":"<pre><code>slaDefaultColumn: tab1.txn_ref_dt # Optional, default value is partitionColumn.\nslaProperties:\n- property: latency # Property, see list of values in DP QoS\nvalue: 4\nunit: d # d, day, days for days; y, yr, years for years\ncolumn: tab1.txn_ref_dt # This would not be needed as it is the same table.column as the default one\n- property: generalAvailability\nvalue: 2022-05-12T09:30:10-08:00\n- property: endOfSupport\nvalue: 2032-05-12T09:30:10-08:00\n- property: endOfLife\nvalue: 2042-05-12T09:30:10-08:00\n- property: retention\nvalue: 3\nunit: y\ncolumn: tab1.txn_ref_dt\n- property: frequency\nvalue: 1\nvalueExt: 1\nunit: d\ncolumn: tab1.txn_ref_dt\n- property: timeOfAvailability\nvalue: 09:00-08:00\ncolumn: tab1.txn_ref_dt\ndriver: regulatory # Describes the importance of the SLA: [regulatory|analytics|operational|...]\n- property: timeOfAvailability\nvalue: 08:00-08:00\ncolumn: tab1.txn_ref_dt\ndriver: analytics\n</code></pre>"},{"location":"standard/#definitions_6","title":"Definitions","text":"Key UX label Required Description slaDefaultColumn Default SLA column(s) No Columns (using the Table.Column notation) to do the checks on. By default, it is the partition column. slaProperties SLA No A list of key/value pairs for SLA specific properties. There is no limit on the type of properties (more details to come). slaProperties.property Property Yes Specific property in SLA, check the periodic table. May requires units (more details to come). slaProperties.value Value Yes Agreement value. The label will change based on the property itself. slaProperties.valueExt Extended value No - unless needed by property Extended agreement value. The label will change based on the property itself. slaProperties.unit Unit No - unless needed by property d, day, days for days; y, yr, years for years, etc. Units use the ISO standard. slaProperties.column Column(s) No Column(s) to check on. Multiple columns should be extremely rare and, if so, separated by commas. slaProperties.driver Driver No Describes the importance of the SLA from the list of: <code>regulatory</code>, <code>analytics</code>, or <code>operational</code>."},{"location":"standard/#other-properties","title":"Other properties","text":"<p>This section covers other properties you may find in a data contract.</p>"},{"location":"standard/#example_6","title":"Example","text":"<pre><code>customProperties:\n- property: refRulesetName\nvalue: gcsc.ruleset.name\n- property: somePropertyName\nvalue: property.value\n- property: dataprocClusterName # Used for specific applications like Elevate\nvalue: [cluster name]\nsystemInstance: instance.ClimateQuantum.org\ncontractCreatedTs: 2022-11-15 02:59:43\n</code></pre>"},{"location":"standard/#definitions_7","title":"Definitions","text":"Key UX label Required Description customProperties Custom Properties No A list of key/value pairs for custom properties. Initially created to support the REF ruleset property. customProperties.property Property No The name of the key. Names should be in camel case\u2013the same as if they were permanent properties in the contract. customProperties.value Value No The value of the key. systemInstance System Instance No System Instance name where the dataset resides. contractCreatedTs Contract Created UTC No Timestamp in UTC of when the data contract was created."},{"location":"standard/#full-example","title":"Full example","text":"<p>Check full example here.</p>"},{"location":"examples/","title":"Examples of Data Contracts","text":""},{"location":"examples/#executive-summary","title":"Executive summary","text":"<p>This folder contains mainly excerpt of data contracts to illustrate specific sections &amp; behaviors.</p>"},{"location":"examples/#table-of-content","title":"Table of content","text":"<ul> <li>Full example</li> <li>Fundamentals &amp; demographics</li> <li>Datasets &amp; schema</li> <li>Data quality</li> <li>Pricing</li> <li>Stakeholders</li> <li>Roles</li> <li>Service-level agreement</li> <li>Other properties</li> </ul>"},{"location":"examples/#full-example","title":"Full example","text":"<ul> <li>Full example</li> <li>Postgres AdventureWorks</li> </ul>"},{"location":"examples/#fundamentals","title":"Fundamentals","text":"<ul> <li>Table and column</li> </ul>"},{"location":"examples/#dataset-and-schema","title":"Dataset and schema","text":"<ul> <li>Table with single column</li> <li>Table with columns and partitioning</li> </ul>"},{"location":"examples/#data-quality","title":"Data quality","text":"<ul> <li>Column accuracy</li> <li>Column completeness</li> <li>Column validity</li> </ul>"},{"location":"examples/#pricing","title":"Pricing","text":"<p>This section covers pricing when you bill your customer for using this data product. Pricing is experimental in v2.2.0 of the data contract.</p>"},{"location":"examples/#stakeholders","title":"Stakeholders","text":"<ul> <li>Stakeholders example</li> </ul>"},{"location":"examples/#roles","title":"Roles","text":"<ul> <li>Service and operational roles</li> </ul>"},{"location":"examples/#service-level-agreement","title":"Service-level agreement","text":"<ul> <li>Database SLA</li> </ul>"},{"location":"examples/#other-properties","title":"Other properties","text":"<p>Coming soon.</p>"}]}